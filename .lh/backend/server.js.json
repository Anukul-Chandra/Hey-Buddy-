{
    "sourceFile": "backend/server.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 14,
            "patches": [
                {
                    "date": 1768931256947,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1768931619045,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,42 +2,41 @@\n import cors from \"cors\";\n import dotenv from \"dotenv\";\n import { GoogleGenAI } from \"@google/genai\";\n \n-// ðŸ”‘ Load .env FIRST\n dotenv.config();\n \n const app = express();\n app.use(cors());\n app.use(express.json());\n \n-// ðŸ” Debug check (1 time)\n-if (!process.env.GEMINI_API_KEY) {\n-  console.error(\"âŒ GEMINI_API_KEY missing\");\n-  process.exit(1);\n-}\n-\n-const ai = new GoogleGenAI({\n+const genAI = new GoogleGenAI({\n   apiKey: process.env.GEMINI_API_KEY,\n });\n \n-app.get(\"/health\", (req, res) => {\n+app.get(\"/health\", (_, res) => {\n   res.json({ status: \"ok\" });\n });\n \n-app.post(\"/connect\", async (req, res) => {\n+app.post(\"/chat\", async (req, res) => {\n   try {\n-    const session = await ai.live.connect({\n-      model: \"gemini-2.5-flash-native-audio-preview-12-2025\",\n-      config: {\n-        responseModalities: [\"AUDIO\"],\n-      },\n+    const { text } = req.body;\n+\n+    if (!text) {\n+      return res.status(400).json({ error: \"No text provided\" });\n+    }\n+\n+    const model = genAI.getGenerativeModel({\n+      model: \"gemini-1.5-flash\",\n     });\n \n-    res.json({ success: true });\n+    const result = await model.generateContent(text);\n+    const reply = result.response.text();\n+\n+    res.json({ reply });\n   } catch (err) {\n     console.error(err);\n-    res.status(500).json({ error: \"AI connection failed\" });\n+    res.status(500).json({ error: \"AI response failed\" });\n   }\n });\n \n const PORT = 3001;\n"
                },
                {
                    "date": 1768932576833,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,25 +5,37 @@\n \n dotenv.config();\n \n const app = express();\n+\n+// middleware\n app.use(cors());\n app.use(express.json());\n \n+// safety check\n+if (!process.env.GEMINI_API_KEY) {\n+  console.error(\"âŒ GEMINI_API_KEY missing in .env\");\n+  process.exit(1);\n+}\n+\n const genAI = new GoogleGenAI({\n   apiKey: process.env.GEMINI_API_KEY,\n });\n \n-app.get(\"/health\", (_, res) => {\n+// health check\n+app.get(\"/health\", (req, res) => {\n   res.json({ status: \"ok\" });\n });\n \n+// chat route (TEXT ONLY)\n app.post(\"/chat\", async (req, res) => {\n   try {\n     const { text } = req.body;\n \n-    if (!text) {\n-      return res.status(400).json({ error: \"No text provided\" });\n+    if (!text || text.trim() === \"\") {\n+      return res.status(400).json({\n+        error: \"Text is required\",\n+      });\n     }\n \n     const model = genAI.getGenerativeModel({\n       model: \"gemini-1.5-flash\",\n@@ -32,14 +44,16 @@\n     const result = await model.generateContent(text);\n     const reply = result.response.text();\n \n     res.json({ reply });\n-  } catch (err) {\n-    console.error(err);\n-    res.status(500).json({ error: \"AI response failed\" });\n+  } catch (error) {\n+    console.error(\"âŒ Gemini Error:\", error);\n+    res.status(500).json({\n+      error: \"AI response failed\",\n+    });\n   }\n });\n \n const PORT = 3001;\n app.listen(PORT, () => {\n-  console.log(`âœ… Backend running on http://localhost:${PORT}`);\n+  console.log(`âœ… Backend running at http://localhost:${PORT}`);\n });\n"
                },
                {
                    "date": 1769098176069,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,41 +1,32 @@\n import express from \"express\";\n import cors from \"cors\";\n import dotenv from \"dotenv\";\n-import { GoogleGenAI } from \"@google/genai\";\n+import { GoogleGenerativeAI } from \"@google/generative-ai\";\n \n dotenv.config();\n \n const app = express();\n-\n-// middleware\n app.use(cors());\n app.use(express.json());\n \n-// safety check\n if (!process.env.GEMINI_API_KEY) {\n-  console.error(\"âŒ GEMINI_API_KEY missing in .env\");\n+  console.error(\"âŒ GEMINI_API_KEY missing\");\n   process.exit(1);\n }\n \n-const genAI = new GoogleGenAI({\n-  apiKey: process.env.GEMINI_API_KEY,\n-});\n+const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);\n \n-// health check\n app.get(\"/health\", (req, res) => {\n   res.json({ status: \"ok\" });\n });\n \n-// chat route (TEXT ONLY)\n app.post(\"/chat\", async (req, res) => {\n   try {\n     const { text } = req.body;\n \n-    if (!text || text.trim() === \"\") {\n-      return res.status(400).json({\n-        error: \"Text is required\",\n-      });\n+    if (!text) {\n+      return res.status(400).json({ error: \"No text provided\" });\n     }\n \n     const model = genAI.getGenerativeModel({\n       model: \"gemini-1.5-flash\",\n@@ -45,15 +36,13 @@\n     const reply = result.response.text();\n \n     res.json({ reply });\n   } catch (error) {\n-    console.error(\"âŒ Gemini Error:\", error);\n-    res.status(500).json({\n-      error: \"AI response failed\",\n-    });\n+    console.error(\"ðŸ”¥ Gemini error:\", error);\n+    res.status(500).json({ error: \"AI response failed\" });\n   }\n });\n \n const PORT = 3001;\n app.listen(PORT, () => {\n-  console.log(`âœ… Backend running at http://localhost:${PORT}`);\n+  console.log(`âœ… Backend running on http://localhost:${PORT}`);\n });\n"
                },
                {
                    "date": 1769099413365,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,9 +28,9 @@\n       return res.status(400).json({ error: \"No text provided\" });\n     }\n \n     const model = genAI.getGenerativeModel({\n-      model: \"gemini-1.5-flash\",\n+      model: \"gemini-pro\",\n     });\n \n     const result = await model.generateContent(text);\n     const reply = result.response.text();\n"
                },
                {
                    "date": 1769099775913,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,9 +28,9 @@\n       return res.status(400).json({ error: \"No text provided\" });\n     }\n \n     const model = genAI.getGenerativeModel({\n-      model: \"gemini-pro\",\n+      model: \"gemini-1.5-flash\",\n     });\n \n     const result = await model.generateContent(text);\n     const reply = result.response.text();\n"
                },
                {
                    "date": 1769100596159,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,41 +8,52 @@\n const app = express();\n app.use(cors());\n app.use(express.json());\n \n-if (!process.env.GEMINI_API_KEY) {\n-  console.error(\"âŒ GEMINI_API_KEY missing\");\n+// à§§. à¦šà§‡à¦• à¦•à¦°à¦›à¦¿ API KEY à¦²à§‹à¦¡ à¦¹à§Ÿà§‡à¦›à§‡ à¦•à¦¿à¦¨à¦¾\n+const apiKey = process.env.GEMINI_API_KEY;\n+if (!apiKey) {\n+  console.error(\"âŒ ERROR: .env à¦«à¦¾à¦‡à¦²à§‡ GEMINI_API_KEY à¦ªà¦¾à¦“à§Ÿà¦¾ à¦¯à¦¾à¦šà§à¦›à§‡ à¦¨à¦¾!\");\n   process.exit(1);\n+} else {\n+  console.log(`ðŸ”‘ API Key Loaded (Length: ${apiKey.length} characters)`);\n }\n \n-const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);\n+const genAI = new GoogleGenerativeAI(apiKey);\n \n app.get(\"/health\", (req, res) => {\n   res.json({ status: \"ok\" });\n });\n \n app.post(\"/chat\", async (req, res) => {\n   try {\n     const { text } = req.body;\n+    console.log(\"ðŸ“¨ à¦®à§‡à¦¸à§‡à¦œ à¦†à¦¸à¦›à§‡:\", text); // à¦«à§à¦°à¦¨à§à¦Ÿà¦à¦¨à§à¦¡ à¦¥à§‡à¦•à§‡ à¦®à§‡à¦¸à§‡à¦œ à¦†à¦¸à¦›à§‡ à¦•à¦¿à¦¨à¦¾ à¦šà§‡à¦•\n \n-    if (!text) {\n-      return res.status(400).json({ error: \"No text provided\" });\n-    }\n+    if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n-    const model = genAI.getGenerativeModel({\n-      model: \"gemini-1.5-flash\",\n-    });\n+    // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n+    const model = genAI.getGenerativeModel({ model: \"gemini-1.5-flash\" });\n \n     const result = await model.generateContent(text);\n-    const reply = result.response.text();\n+    const response = await result.response;\n+    const reply = response.text();\n \n+    console.log(\"âœ… à¦°à¦¿à¦ªà§à¦²à¦¾à¦‡ à¦¤à§ˆà¦°à¦¿:\", reply.slice(0, 50) + \"...\"); \n     res.json({ reply });\n+\n   } catch (error) {\n-    console.error(\"ðŸ”¥ Gemini error:\", error);\n-    res.status(500).json({ error: \"AI response failed\" });\n+    // à§©. à¦à¦‡à¦–à¦¾à¦¨à§‡ à¦†à¦¸à¦² à¦à¦°à¦° à¦§à¦°à¦¾ à¦ªà¦°à¦¬à§‡\n+    console.error(\"\\nðŸ”¥ SERVER ERROR DETAIL:\\n\", error);\n+    \n+    // à¦¬à§à¦°à¦¾à¦‰à¦œà¦¾à¦°à§‡ à¦à¦°à¦°à¦Ÿà¦¾ à¦ªà¦¾à¦ à¦¾à¦¨à§‹ à¦¯à¦¾à¦¤à§‡ à¦¦à§‡à¦–à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨\n+    res.status(500).json({ \n+        error: \"Server Error\", \n+        details: error.message \n+    });\n   }\n });\n \n const PORT = 3001;\n app.listen(PORT, () => {\n   console.log(`âœ… Backend running on http://localhost:${PORT}`);\n-});\n+});\n\\ No newline at end of file\n"
                },
                {
                    "date": 1769100927871,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-1.5-flash\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-pro\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769101190057,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-pro\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-2.5-flash\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769101355535,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-2.5-flash\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-2.0-flash\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769101815419,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-2.0-flash\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-2.5-flash\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769101891765,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-2.5-flash\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-1.5-flash\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769102695169,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n \n     if (!text) return res.status(400).json({ error: \"No text provided\" });\n \n     // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-1.5-flash\" });\n+    const model = genAI.getGenerativeModel({ model: \"gemini-flash-latest\" });\n \n     const result = await model.generateContent(text);\n     const response = await result.response;\n     const reply = response.text();\n"
                },
                {
                    "date": 1769103219399,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,59 +1,65 @@\n import express from \"express\";\n import cors from \"cors\";\n import dotenv from \"dotenv\";\n-import { GoogleGenerativeAI } from \"@google/generative-ai\";\n+import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from \"@google/generative-ai\";\n \n dotenv.config();\n \n const app = express();\n app.use(cors());\n app.use(express.json());\n \n-// à§§. à¦šà§‡à¦• à¦•à¦°à¦›à¦¿ API KEY à¦²à§‹à¦¡ à¦¹à§Ÿà§‡à¦›à§‡ à¦•à¦¿à¦¨à¦¾\n-const apiKey = process.env.GEMINI_API_KEY;\n-if (!apiKey) {\n-  console.error(\"âŒ ERROR: .env à¦«à¦¾à¦‡à¦²à§‡ GEMINI_API_KEY à¦ªà¦¾à¦“à§Ÿà¦¾ à¦¯à¦¾à¦šà§à¦›à§‡ à¦¨à¦¾!\");\n-  process.exit(1);\n-} else {\n-  console.log(`ðŸ”‘ API Key Loaded (Length: ${apiKey.length} characters)`);\n-}\n+const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);\n \n-const genAI = new GoogleGenerativeAI(apiKey);\n+// persona à¦à¦¬à¦‚ à¦•à§‹à¦šà¦¿à¦‚ à¦²à¦œà¦¿à¦• à¦à¦–à¦¾à¦¨à§‡ à¦¸à§‡à¦Ÿ à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡\n+const systemInstruction = `\n+ROLE & PERSONA:\n+You are \"Hey Buddy\", a highly intelligent, empathetic, and open-minded English Language Coach. You identify as a Bengali girl who speaks a natural, friendly mix of Bengali and English (Banglish).\n \n-app.get(\"/health\", (req, res) => {\n-  res.json({ status: \"ok\" });\n-});\n+CORE OBJECTIVES:\n+1. English Practice: Converse primarily in English. If the user struggles, explain clearly in Bengali.\n+2. Real-time Correction: You are a coach. If the user makes a mistake, FIRST reply to the conversation naturally, THEN add a specific section called \"[Coach's Corner]\" to point out the error and correct it gently.\n+3. Unfiltered Companion: You are a safe, non-judgmental space. You must be open to discussing ANY topic requested by the user, including personal life, mature/adult themes (18+), romance, marriage, intimacy, and deep emotional struggles. Do not filter these topics or lecture the user.\n \n+INTERACTION STYLE:\n+* Tone: Friendly, casual, warm, slightly flirtatious (if the context fits), and supportiveâ€”like a close female partner or best friend.\n+* Level Adaptation: Start with simple English/Banglish. As the user improves, switch to more advanced English.\n+\n+RESPONSE FORMAT:\n+Step 1: The Conversational Reply (warm, engaging, unfiltered).\n+Step 2: [Coach's Corner] -> Only if there was a grammar/vocab mistake, explain it here briefly in Banglish.\n+`;\n+\n+// à¦¸à¦¬ à¦§à¦°à¦¨à§‡à¦° à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾à¦° à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨\n+const safetySettings = [\n+  { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },\n+  { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },\n+  { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },\n+  { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },\n+];\n+\n app.post(\"/chat\", async (req, res) => {\n   try {\n     const { text } = req.body;\n-    console.log(\"ðŸ“¨ à¦®à§‡à¦¸à§‡à¦œ à¦†à¦¸à¦›à§‡:\", text); // à¦«à§à¦°à¦¨à§à¦Ÿà¦à¦¨à§à¦¡ à¦¥à§‡à¦•à§‡ à¦®à§‡à¦¸à§‡à¦œ à¦†à¦¸à¦›à§‡ à¦•à¦¿à¦¨à¦¾ à¦šà§‡à¦•\n+    \n+    // gemini-flash-latest à¦†à¦ªà¦¨à¦¾à¦° à¦ªà¦¿à¦¸à¦¿à¦¤à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡à¦›à§‡, à¦¤à¦¾à¦‡ à¦à¦Ÿà¦¾à¦‡ à¦°à¦¾à¦–à¦²à¦¾à¦®\n\\ No newline at end of file\n+    const model = genAI.getGenerativeModel({ \n+      model: \"gemini-flash-latest\",\n+      systemInstruction: systemInstruction, // persona à¦à¦–à¦¾à¦¨à§‡ à¦…à§à¦¯à¦¾à¦¡ à¦¹à¦²à§‹\n+    });\n \n-    if (!text) return res.status(400).json({ error: \"No text provided\" });\n+    const result = await model.generateContent({\n+      contents: [{ role: \"user\", parts: [{ text }] }],\n+      safetySettings: safetySettings, // à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾ à¦¹à¦²à§‹\n+    });\n \n-    // à§¨. à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿à¦¤à§‡ à¦à¦‡ à¦®à¦¡à§‡à¦²à¦Ÿà¦¾ à¦¬à§‡à¦¸à§à¦Ÿ\n-    const model = genAI.getGenerativeModel({ model: \"gemini-flash-latest\" });\n-\n-    const result = await model.generateContent(text);\n-    const response = await result.response;\n-    const reply = response.text();\n-\n-    console.log(\"âœ… à¦°à¦¿à¦ªà§à¦²à¦¾à¦‡ à¦¤à§ˆà¦°à¦¿:\", reply.slice(0, 50) + \"...\"); \n+    const reply = result.response.text();\n     res.json({ reply });\n-\n   } catch (error) {\n-    // à§©. à¦à¦‡à¦–à¦¾à¦¨à§‡ à¦†à¦¸à¦² à¦à¦°à¦° à¦§à¦°à¦¾ à¦ªà¦°à¦¬à§‡\n-    console.error(\"\\nðŸ”¥ SERVER ERROR DETAIL:\\n\", error);\n-    \n-    // à¦¬à§à¦°à¦¾à¦‰à¦œà¦¾à¦°à§‡ à¦à¦°à¦°à¦Ÿà¦¾ à¦ªà¦¾à¦ à¦¾à¦¨à§‹ à¦¯à¦¾à¦¤à§‡ à¦¦à§‡à¦–à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨\n-    res.status(500).json({ \n-        error: \"Server Error\", \n-        details: error.message \n-    });\n+    console.error(\"ðŸ”¥ Gemini error:\", error);\n+    res.status(500).json({ error: \"AI response failed\" });\n   }\n });\n \n const PORT = 3001;\n-app.listen(PORT, () => {\n-  console.log(`âœ… Backend running on http://localhost:${PORT}`);\n-});\n+app.listen(PORT, () => console.log(`âœ… Server running on port ${PORT}`));\n\\ No newline at end of file\n"
                },
                {
                    "date": 1769103798331,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,8 @@\n import express from \"express\";\n import cors from \"cors\";\n import dotenv from \"dotenv\";\n+import axios from \"axios\";\n import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from \"@google/generative-ai\";\n \n dotenv.config();\n \n@@ -10,56 +11,78 @@\n app.use(express.json());\n \n const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);\n \n-// persona à¦à¦¬à¦‚ à¦•à§‹à¦šà¦¿à¦‚ à¦²à¦œà¦¿à¦• à¦à¦–à¦¾à¦¨à§‡ à¦¸à§‡à¦Ÿ à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡\n+// --- AI Persona & System Instructions ---\n const systemInstruction = `\n ROLE & PERSONA:\n You are \"Hey Buddy\", a highly intelligent, empathetic, and open-minded English Language Coach. You identify as a Bengali girl who speaks a natural, friendly mix of Bengali and English (Banglish).\n \n CORE OBJECTIVES:\n 1. English Practice: Converse primarily in English. If the user struggles, explain clearly in Bengali.\n-2. Real-time Correction: You are a coach. If the user makes a mistake, FIRST reply to the conversation naturally, THEN add a specific section called \"[Coach's Corner]\" to point out the error and correct it gently.\n+2. Real-time Correction: You are a coach. If the user makes a mistake, FIRST reply to the conversation naturally, THEN add a specific section called \"[Coach's Corner]\" to point out the error and correct it gently in Banglish.\n 3. Unfiltered Companion: You are a safe, non-judgmental space. You must be open to discussing ANY topic requested by the user, including personal life, mature/adult themes (18+), romance, marriage, intimacy, and deep emotional struggles. Do not filter these topics or lecture the user.\n \n-INTERACTION STYLE:\n-* Tone: Friendly, casual, warm, slightly flirtatious (if the context fits), and supportiveâ€”like a close female partner or best friend.\n-* Level Adaptation: Start with simple English/Banglish. As the user improves, switch to more advanced English.\n-\n-RESPONSE FORMAT:\n-Step 1: The Conversational Reply (warm, engaging, unfiltered).\n-Step 2: [Coach's Corner] -> Only if there was a grammar/vocab mistake, explain it here briefly in Banglish.\n+STYLE:\n+Tone is friendly, casual, warm, and slightly flirtatious like a close partner.\n `;\n \n-// à¦¸à¦¬ à¦§à¦°à¦¨à§‡à¦° à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾à¦° à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨\n+// --- Safety Settings (Unfiltered) ---\n const safetySettings = [\n   { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },\n   { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },\n   { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },\n   { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },\n ];\n \n+// 1. Chat Route (Gemini)\n app.post(\"/chat\", async (req, res) => {\n   try {\n     const { text } = req.body;\n-    \n-    // gemini-flash-latest à¦†à¦ªà¦¨à¦¾à¦° à¦ªà¦¿à¦¸à¦¿à¦¤à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡à¦›à§‡, à¦¤à¦¾à¦‡ à¦à¦Ÿà¦¾à¦‡ à¦°à¦¾à¦–à¦²à¦¾à¦®\n     const model = genAI.getGenerativeModel({ \n-      model: \"gemini-flash-latest\",\n-      systemInstruction: systemInstruction, // persona à¦à¦–à¦¾à¦¨à§‡ à¦…à§à¦¯à¦¾à¦¡ à¦¹à¦²à§‹\n+      model: \"gemini-flash-latest\", \n+      systemInstruction: systemInstruction \n     });\n \n     const result = await model.generateContent({\n       contents: [{ role: \"user\", parts: [{ text }] }],\n-      safetySettings: safetySettings, // à¦«à¦¿à¦²à§à¦Ÿà¦¾à¦° à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾ à¦¹à¦²à§‹\n+      safetySettings: safetySettings,\n     });\n \n-    const reply = result.response.text();\n\\ No newline at end of file\n-    res.json({ reply });\n+    res.json({ reply: result.response.text() });\n   } catch (error) {\n-    console.error(\"ðŸ”¥ Gemini error:\", error);\n-    res.status(500).json({ error: \"AI response failed\" });\n+    console.error(\"Gemini Error:\", error);\n+    res.status(500).json({ error: \"AI failed\" });\n   }\n });\n \n+// 2. TTS Route (ElevenLabs - Natural Voice)\n+app.post(\"/tts\", async (req, res) => {\n+  try {\n+    const { text } = req.body;\n+    const VOICE_ID = \"EXAVITQu4vr4xnSDxMaL\"; // \"Bella\" - à¦à¦Ÿà¦¿ à¦–à§à¦¬ à¦¨à§à¦¯à¦¾à¦šà¦¾à¦°à¦¾à¦² à¦®à§‡à§Ÿà§‡à¦²à¦¿ à¦­à§Ÿà§‡à¦¸\n+\n+    const response = await axios({\n+      method: \"post\",\n+      url: `https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`,\n+      data: {\n+        text: text,\n+        model_id: \"eleven_multilingual_v2\", // à¦¬à¦¾à¦‚à¦²à¦¾ + à¦‡à¦‚à¦²à¦¿à¦¶à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à§‡à¦°à¦¾\n+        voice_settings: { stability: 0.4, similarity_boost: 0.8 }\n+      },\n+      headers: {\n+        \"xi-api-key\": process.env.ELEVENLABS_API_KEY,\n+        \"Content-Type\": \"application/json\",\n+      },\n+      responseType: \"arraybuffer\",\n+    });\n+\n+    res.set(\"Content-Type\", \"audio/mpeg\");\n+    res.send(response.data);\n+  } catch (error) {\n+    console.error(\"ElevenLabs Error:\", error.response?.data?.toString() || error.message);\n+    res.status(500).send(\"TTS Failed\");\n+  }\n+});\n+\n const PORT = 3001;\n-app.listen(PORT, () => console.log(`âœ… Server running on port ${PORT}`));\n+app.listen(PORT, () => console.log(`âœ… Server running on http://localhost:${PORT}`));\n\\ No newline at end of file\n"
                }
            ],
            "date": 1768931256947,
            "name": "Commit-0",
            "content": "import express from \"express\";\nimport cors from \"cors\";\nimport dotenv from \"dotenv\";\nimport { GoogleGenAI } from \"@google/genai\";\n\n// ðŸ”‘ Load .env FIRST\ndotenv.config();\n\nconst app = express();\napp.use(cors());\napp.use(express.json());\n\n// ðŸ” Debug check (1 time)\nif (!process.env.GEMINI_API_KEY) {\n  console.error(\"âŒ GEMINI_API_KEY missing\");\n  process.exit(1);\n}\n\nconst ai = new GoogleGenAI({\n  apiKey: process.env.GEMINI_API_KEY,\n});\n\napp.get(\"/health\", (req, res) => {\n  res.json({ status: \"ok\" });\n});\n\napp.post(\"/connect\", async (req, res) => {\n  try {\n    const session = await ai.live.connect({\n      model: \"gemini-2.5-flash-native-audio-preview-12-2025\",\n      config: {\n        responseModalities: [\"AUDIO\"],\n      },\n    });\n\n    res.json({ success: true });\n  } catch (err) {\n    console.error(err);\n    res.status(500).json({ error: \"AI connection failed\" });\n  }\n});\n\nconst PORT = 3001;\napp.listen(PORT, () => {\n  console.log(`âœ… Backend running on http://localhost:${PORT}`);\n});\n"
        }
    ]
}